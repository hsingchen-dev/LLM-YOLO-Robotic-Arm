Languages: [日本語](README_ja.md) | [English](README.md)

# LLM-YOLO-Robotic-Arm  
LLM（ChatGPT）とYOLOを活用した音声制御ロボットアームシステム

---

# はじめに（Introduction）  

私たちは、生成AIと日本の伝統的な自動化技術の融合を研究する学際的なチームです。  
本プロジェクトの目的は、ChatGPT、YOLO、逆運動学を組み合わせることで、ロボットアームが自然言語の命令を理解し、日本の高度な自動化システムと連携して適切な動作を実行できるようにすることです。  

本研究の主なテーマは以下のとおりです：  
- **自然言語処理（NLP）：** 大型言語モデル（LLM）による意味解析  
- **コンピュータビジョン（CV）：** YOLOによる物体認識  
- **ロボット制御：** 逆運動学によるロボットアームの動作計算  
- **ヒューマン・ロボット・インタラクション：** 音声入力と動作指示の最適化  

 
本プロジェクトは、成果の中核は神戸大学学生に帰属します。
本プロジェクトは、AIとロボティクスの融合による「次世代スマート制御」の実証モデルを目指しています。

---

# Agent-SKYNET  

Sky Netは、LLM（大型言語モデル）と現実世界のロボット制御をつなぐために私たちのチームが開発したモジュール型のソフトウェアエージェントです。  
自然言語と機械の動作の間における知能的インターフェースとして機能し、Sky NetはChatGPTを中核の推論エンジンとして使用しています。音声またはテキストコマンドを受け取ると、意味解析・文脈理解・意思決定を行い、物体認識モジュール（YOLO）および制御レイヤー（逆運動学・サーボ制御）と連携して、6自由度のロボットアームを介して適切な物理的動作を実行します。

このアーキテクチャにより、リアルタイムかつ直感的な人間とロボットのインタラクションが実現され、言語駆動による物体操作が可能になります。  
Sky Netは、「言語を理解するだけでなく、現実世界で意味のある行動をとるAI」すなわち**身体性を持つAI（Embodied AI）**への一歩となります。

---

# 概要（Overview）  

LLM-Robotic-Armは、YOLOによる物体認識とChatGPTによる自然言語理解を統合し、音声ガイドによる6自由度ロボットアームの制御を実現するシステムです。  
本システムは、リアルタイム物体認識、ソケット通信、逆運動学による正確な動作制御をサポートしています。  
本システムは、視覚・言語・動作の3要素を統合するマルチモーダルAIロボット制御の実例として注目されています。

---

# 特徴（Features）

- 音声ベースの物体操作  
- YOLOによるリアルタイム物体検出  
- ChatGPT（LLM）による自然言語理解  
- Raspberry Piベースのデプロイ  
- 逆運動学とサーボ制御対応  

---

# チーム（Team）

本プロジェクトは、博士課程および修士課程の学生による学際的チームによって構成されており、各メンバーが専門分野に基づいて役割を分担しています。

- **杭 星辰（ハン シンチェン）**（プロジェクトリーダー）– ロボットアーム制御、逆運動学、YOLO統合、LLMベースシステム設計を担当。社会向けプレゼン経験、国際共同研究経験。  
  *神戸大学*

- **杭 星辰（ハン シンチェン）**（プロジェクトリーダー）– ロボットアーム制御、逆運動学、YOLO統合、LLMベースシステム設計を担当。社会向けプレゼン経験、国際共同研究経験。  
  *神戸大学*

- **丸山 晴樹（マルヤマ ハルキ）** エージェントによる提示詞処理と、日本語における対話スタイルの調整を担当。自然な日本語応答の設計と文化的文脈の理解を支援。
  *東京大学*

- **李 天洋（リ テンヨウ）** – 3Dモデリング（CAD/SolidWorks）、ロボットの機械設計およびプロトタイピングを担当。YOLOベースの把持と逆運動学の調整も担当。  
  *神戸大学*

- **孫 羽杉（ソン ユシャン）** – システム統合、ソケット通信、バックエンド開発を担当。  
  *神戸大学*

- **孫 妍（ソン ケン）** – 人間行動とロボットインタラクションの研究者であり、システムの行動ロジックを設計。  
  *神戸大学*

- **姜 啓龍（キョウ ケイリュウ）** – Streamlit UI設計およびUX体験の最適化を担当。  
  *デザインおよびソフトウェア工学の背景を持つ*





## 実演ビデオ SKYNET-5  
https://www.youtube.com/watch?v=69e78PqmeNM&t=3s  
本バージョンでは、システムが簡単な言語指令を理解し、それに応じた物理的動作を実行できます。

## 実演ビデオ SKYNET-6  
https://www.youtube.com/watch?v=lS7rUFcXonQ  
このバージョンでは、LLMが人間の行動、認知、心理を学習し、人間らしい意識の要素をシミュレーションします。日本語の敬語理解も含まれています。

## 実演ビデオ SKYNET-6.1  
https://www.youtube.com/watch?v=jr8Sl4M8Fsw  
このバージョンでは、音声制御が追加されています。

## 実演ビデオ SKYNET-8  
https://www.youtube.com/watch?v=Eo-8q8rrNC4  
YOLOベースの物体検出と逆運動学が統合され、単純な物体を認識し、把持動作を実行できます。

---

# 注意（Notice）  
本リポジトリは、現在特許出願準備中の技術に関するポートフォリオの一部です。
そのため、ソースコードの全ては公開しておりません。
共同研究・導入検討などのご相談は、お気軽にご連絡ください。


